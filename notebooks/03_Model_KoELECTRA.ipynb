{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-24T08:17:23.861295Z",
     "start_time": "2025-11-24T08:17:22.541768Z"
    }
   },
   "source": [
    "# ë”¥ëŸ¬ë‹ ë° NLP ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "# (ì´ë¯¸ ì„¤ì¹˜ë˜ì–´ ìˆë‹¤ë©´ ì´ ì…€ì€ ê±´ë„ˆë›°ì–´ë„ ë©ë‹ˆë‹¤)\n",
    "!pip install torch transformers scikit-learn pandas tqdm"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\user\\pycharmprojects\\cosmetics_project\\.venv1\\lib\\site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: transformers in c:\\users\\user\\pycharmprojects\\cosmetics_project\\.venv1\\lib\\site-packages (4.57.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\pycharmprojects\\cosmetics_project\\.venv1\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\pycharmprojects\\cosmetics_project\\.venv1\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\pycharmprojects\\cosmetics_project\\.venv1\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\pycharmprojects\\cosmetics_project\\.venv1\\lib\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\user\\pycharmprojects\\cosmetics_project\\.venv1\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\pycharmprojects\\cosmetics_project\\.venv1\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\pycharmprojects\\cosmetics_project\\.venv1\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\pycharmprojects\\cosmetics_project\\.venv1\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\user\\pycharmprojects\\cosmetics_project\\.venv1\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\pycharmprojects\\cosmetics_project\\.venv1\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\user\\pycharmprojects\\cosmetics_project\\.venv1\\lib\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\pycharmprojects\\cosmetics_project\\.venv1\\lib\\site-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\pycharmprojects\\cosmetics_project\\.venv1\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\pycharmprojects\\cosmetics_project\\.venv1\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\pycharmprojects\\cosmetics_project\\.venv1\\lib\\site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\pycharmprojects\\cosmetics_project\\.venv1\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\user\\pycharmprojects\\cosmetics_project\\.venv1\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\user\\pycharmprojects\\cosmetics_project\\.venv1\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\user\\pycharmprojects\\cosmetics_project\\.venv1\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\pycharmprojects\\cosmetics_project\\.venv1\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\user\\pycharmprojects\\cosmetics_project\\.venv1\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\pycharmprojects\\cosmetics_project\\.venv1\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\pycharmprojects\\cosmetics_project\\.venv1\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\pycharmprojects\\cosmetics_project\\.venv1\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\pycharmprojects\\cosmetics_project\\.venv1\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\pycharmprojects\\cosmetics_project\\.venv1\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\pycharmprojects\\cosmetics_project\\.venv1\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\pycharmprojects\\cosmetics_project\\.venv1\\lib\\site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\pycharmprojects\\cosmetics_project\\.venv1\\lib\\site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\pycharmprojects\\cosmetics_project\\.venv1\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\pycharmprojects\\cosmetics_project\\.venv1\\lib\\site-packages (from requests->transformers) (2025.11.12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T08:17:23.877348Z",
     "start_time": "2025-11-24T08:17:23.861295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# 1. ì—¬ê¸°ì„œ AdamWë¥¼ ì§€ì›ë‹ˆë‹¤.\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "# 2. ëŒ€ì‹  ì—¬ê¸°ì„œ AdamWë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. (PyTorch ë‚´ì¥ ìµœì í™” í•¨ìˆ˜ ì‚¬ìš©)\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"í˜„ì¬ ì‚¬ìš© ì¥ì¹˜: {device}\")\n",
    "\n",
    "# ê²½ë¡œ ì„¤ì •\n",
    "DATA_PATH =\"../data/03_final/train_data.csv\"\n",
    "MODEL_SAVE_PATH = \"../models/koelectra_finetuned/\"\n",
    "\n",
    "os.makedirs(MODEL_SAVE_PATH, exist_ok=True)"
   ],
   "id": "813b3c1f042024b6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í˜„ì¬ ì‚¬ìš© ì¥ì¹˜: cuda\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T08:17:26.455596Z",
     "start_time": "2025-11-24T08:17:23.893117Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install openpyxl\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# íŒŒì¼ ê²½ë¡œ\n",
    "ORIGINAL_PATH = \"../data/03_final/train_data.csv\"  # í˜„ì¬ ê¹¨ì§€ëŠ” íŒŒì¼\n",
    "FIXED_PATH = \"../data/03_final/train_data_fixed.csv\" # ìƒˆë¡œ ë§Œë“¤ ì§„ì§œ CSV\n",
    "\n",
    "print(f\"ğŸ“‚ íŒŒì¼ ë³µêµ¬ ë° ë¡œë“œ ì‹œë„: {ORIGINAL_PATH}\")\n",
    "\n",
    "try:\n",
    "    # 1. í™•ì¥ìëŠ” .csvì§€ë§Œ ì‹¤ì œë¡  ì—‘ì…€ íŒŒì¼ì´ë¯€ë¡œ 'read_excel'ë¡œ ì½ìŠµë‹ˆë‹¤.\n",
    "    df = pd.read_excel(ORIGINAL_PATH, engine='openpyxl')\n",
    "    print(\"âœ… ì—‘ì…€ í˜•ì‹ìœ¼ë¡œ ì½ê¸° ì„±ê³µ!\")\n",
    "\n",
    "    # 2. ì½ì€ ë°ì´í„°ë¥¼ 'ì§„ì§œ CSV'ë¡œ ë‹¤ì‹œ ì €ì¥í•©ë‹ˆë‹¤ (ë‚˜ì¤‘ì„ ìœ„í•´)\n",
    "    df.to_csv(FIXED_PATH, index=False, encoding='utf-8-sig')\n",
    "    print(f\"âœ… ì •ìƒì ì¸ CSV íŒŒì¼ë¡œ ë³€í™˜ ì™„ë£Œ: {FIXED_PATH}\")\n",
    "\n",
    "    # 3. ë°ì´í„° í™•ì¸\n",
    "    print(f\"ë¡œë“œëœ ë°ì´í„° ê°œìˆ˜: {len(df)}ê±´\")\n",
    "    print(f\"ì»¬ëŸ¼ ëª©ë¡: {df.columns.tolist()}\")\n",
    "    display(df.head(3))\n",
    "\n",
    "    # --- ì „ì²˜ë¦¬ ë° ë°ì´í„° ë¶„ë¦¬ ---\n",
    "    text_col = 'cleaned_review' if 'cleaned_review' in df.columns else 'review'\n",
    "\n",
    "    if text_col in df.columns and 'label' in df.columns:\n",
    "        df = df[[text_col, 'label']].dropna()\n",
    "        df['label'] = pd.to_numeric(df['label'], errors='coerce')\n",
    "        df = df.dropna(subset=['label'])\n",
    "        df['label'] = df['label'].astype(int)\n",
    "\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "            df[text_col].tolist(),\n",
    "            df['label'].tolist(),\n",
    "            test_size=0.2,\n",
    "            random_state=42,\n",
    "            stratify=df['label']\n",
    "        )\n",
    "        print(\"-\" * 30)\n",
    "        print(f\"í•™ìŠµ ë°ì´í„°: {len(train_texts)}ê°œ, ê²€ì¦ ë°ì´í„°: {len(val_texts)}ê°œ\")\n",
    "        print(\"ì¤€ë¹„ ì™„ë£Œ! ë‹¤ìŒ ì…€([Cell 4])ë¡œ ë„˜ì–´ê°€ì„¸ìš”.\")\n",
    "    else:\n",
    "        print(f\"âŒ ì˜¤ë¥˜: '{text_col}' ë˜ëŠ” 'label' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ì»¬ëŸ¼ëª…ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "    print(\"íŒ: '!pip install openpyxl'ì„ ë¨¼ì € ì‹¤í–‰í–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.\")"
   ],
   "id": "f058431bc3695e45",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxlğŸ“‚ íŒŒì¼ ë³µêµ¬ ë° ë¡œë“œ ì‹œë„: ../data/03_final/train_data.csv\n",
      "\n",
      "  Using cached openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Using cached et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Using cached openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Using cached et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   ---------------------------------------- 2/2 [openpyxl]\n",
      "\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì—‘ì…€ í˜•ì‹ìœ¼ë¡œ ì½ê¸° ì„±ê³µ!\n",
      "âœ… ì •ìƒì ì¸ CSV íŒŒì¼ë¡œ ë³€í™˜ ì™„ë£Œ: ../data/03_final/train_data_fixed.csv\n",
      "ë¡œë“œëœ ë°ì´í„° ê°œìˆ˜: 2500ê±´\n",
      "ì»¬ëŸ¼ ëª©ë¡: ['Unnamed: 0', 'product_name', 'rating', 'skin_type', 'review', 'cleaned_review', 'id', 'label']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   Unnamed: 0                                 product_name  rating skin_type  \\\n",
       "0      119258              êµ¬ë‹¬ ì²­ê·¤ ë¹„íƒ€C í¬ë¦¼ 50ml (ì•„ì´í¬ë¦¼15ml ì¦ì •)       5       ë³µí•©ì„±   \n",
       "1       75013                      ì•„ë²¤ëŠ ë˜˜ë ˆë‘ìŠ¤ ì»¨íŠ¸ë¡¤ í¬ë¦¼ 40ml ê¸°íš       5        ê±´ì„±   \n",
       "2       97775  ë¦¬ì–¼ë² ë¦¬ì–´ ì¸í…ìŠ¤ ëª¨ì´ìŠ¤ì²˜ í¬ë¦¼ ê¸°íš (ë³¸í’ˆ50ml+20ml+í¼50ml ì¦ì •)       5       NaN   \n",
       "\n",
       "                                              review  \\\n",
       "0  êµ¬ë‹¬ì˜Â ë‹¤ë¥¸Â ì œí’ˆì„Â ì¼ì„ë•ŒÂ í–¥ë„Â ì¢‹ê³ Â ë¯¸ë°±íš¨ê³¼ë„Â ì¢€Â ë³¸ê²ƒê°™ì•„ì„œÂ êµ¬ë§¤í–ˆìŠµë‹ˆë‹¤.Â ì´Â ì œ...   \n",
       "1  ì•„ë²¤ëŠÂ ì œí’ˆì€Â í”„ë‘ìŠ¤Â ì•½êµ­Â ë¸Œëœë“œÂ ì œí’ˆìœ¼ë¡œÂ ì›Œë‚™Â ìœ ëª…í•´ì„œÂ í•œë²ˆÂ ì¨ë³´ë ¤ê³ Â í–ˆëŠ”ë°Â ì¢‹ì€...   \n",
       "2  ëª‡ë…„ì§¸Â ê¾¸ì¤€í•˜ê²ŒÂ ì“°ê³ Â ìˆì–´ìš”Â ì´ê±°ë³´ë‹¤Â ë‚˜ì€ê±´Â ì•„ì§Â ëª»Â ì°¾ì•˜ë„¤ìš”..Â ì˜¬ë¦¬ë¸Œì˜ì—ì„œÂ ì‚¬ë©´...   \n",
       "\n",
       "                                      cleaned_review  id  label  \n",
       "0  êµ¬ë‹¬ì˜ ë‹¤ë¥¸ ì œí’ˆì„ ì¼ì„ë•Œ í–¥ë„ ì¢‹ê³  ë¯¸ë°±íš¨ê³¼ë„ ì¢€ ë³¸ê²ƒê°™ì•„ì„œ êµ¬ë§¤í–ˆìŠµë‹ˆë‹¤. ì´ ì œ...   0      2  \n",
       "1  ì•„ë²¤ëŠ ì œí’ˆì€ í”„ë‘ìŠ¤ ì•½êµ­ ë¸Œëœë“œ ì œí’ˆìœ¼ë¡œ ì›Œë‚™ ìœ ëª…í•´ì„œ í•œë²ˆ ì¨ë³´ë ¤ê³  í–ˆëŠ”ë° ì¢‹ì€...   1      0  \n",
       "2  ëª‡ë…„ì§¸ ê¾¸ì¤€í•˜ê²Œ ì“°ê³  ìˆì–´ìš” ì´ê±°ë³´ë‹¤ ë‚˜ì€ê±´ ì•„ì§ ëª» ì°¾ì•˜ë„¤ìš”.. ì˜¬ë¦¬ë¸Œì˜ì—ì„œ ì‚¬ë©´...   2      4  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>product_name</th>\n",
       "      <th>rating</th>\n",
       "      <th>skin_type</th>\n",
       "      <th>review</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119258</td>\n",
       "      <td>êµ¬ë‹¬ ì²­ê·¤ ë¹„íƒ€C í¬ë¦¼ 50ml (ì•„ì´í¬ë¦¼15ml ì¦ì •)</td>\n",
       "      <td>5</td>\n",
       "      <td>ë³µí•©ì„±</td>\n",
       "      <td>êµ¬ë‹¬ì˜Â ë‹¤ë¥¸Â ì œí’ˆì„Â ì¼ì„ë•ŒÂ í–¥ë„Â ì¢‹ê³ Â ë¯¸ë°±íš¨ê³¼ë„Â ì¢€Â ë³¸ê²ƒê°™ì•„ì„œÂ êµ¬ë§¤í–ˆìŠµë‹ˆë‹¤.Â ì´Â ì œ...</td>\n",
       "      <td>êµ¬ë‹¬ì˜ ë‹¤ë¥¸ ì œí’ˆì„ ì¼ì„ë•Œ í–¥ë„ ì¢‹ê³  ë¯¸ë°±íš¨ê³¼ë„ ì¢€ ë³¸ê²ƒê°™ì•„ì„œ êµ¬ë§¤í–ˆìŠµë‹ˆë‹¤. ì´ ì œ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75013</td>\n",
       "      <td>ì•„ë²¤ëŠ ë˜˜ë ˆë‘ìŠ¤ ì»¨íŠ¸ë¡¤ í¬ë¦¼ 40ml ê¸°íš</td>\n",
       "      <td>5</td>\n",
       "      <td>ê±´ì„±</td>\n",
       "      <td>ì•„ë²¤ëŠÂ ì œí’ˆì€Â í”„ë‘ìŠ¤Â ì•½êµ­Â ë¸Œëœë“œÂ ì œí’ˆìœ¼ë¡œÂ ì›Œë‚™Â ìœ ëª…í•´ì„œÂ í•œë²ˆÂ ì¨ë³´ë ¤ê³ Â í–ˆëŠ”ë°Â ì¢‹ì€...</td>\n",
       "      <td>ì•„ë²¤ëŠ ì œí’ˆì€ í”„ë‘ìŠ¤ ì•½êµ­ ë¸Œëœë“œ ì œí’ˆìœ¼ë¡œ ì›Œë‚™ ìœ ëª…í•´ì„œ í•œë²ˆ ì¨ë³´ë ¤ê³  í–ˆëŠ”ë° ì¢‹ì€...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97775</td>\n",
       "      <td>ë¦¬ì–¼ë² ë¦¬ì–´ ì¸í…ìŠ¤ ëª¨ì´ìŠ¤ì²˜ í¬ë¦¼ ê¸°íš (ë³¸í’ˆ50ml+20ml+í¼50ml ì¦ì •)</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ëª‡ë…„ì§¸Â ê¾¸ì¤€í•˜ê²ŒÂ ì“°ê³ Â ìˆì–´ìš”Â ì´ê±°ë³´ë‹¤Â ë‚˜ì€ê±´Â ì•„ì§Â ëª»Â ì°¾ì•˜ë„¤ìš”..Â ì˜¬ë¦¬ë¸Œì˜ì—ì„œÂ ì‚¬ë©´...</td>\n",
       "      <td>ëª‡ë…„ì§¸ ê¾¸ì¤€í•˜ê²Œ ì“°ê³  ìˆì–´ìš” ì´ê±°ë³´ë‹¤ ë‚˜ì€ê±´ ì•„ì§ ëª» ì°¾ì•˜ë„¤ìš”.. ì˜¬ë¦¬ë¸Œì˜ì—ì„œ ì‚¬ë©´...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "í•™ìŠµ ë°ì´í„°: 2000ê°œ, ê²€ì¦ ë°ì´í„°: 500ê°œ\n",
      "ì¤€ë¹„ ì™„ë£Œ! ë‹¤ìŒ ì…€([Cell 4])ë¡œ ë„˜ì–´ê°€ì„¸ìš”.\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T08:17:27.126039Z",
     "start_time": "2025-11-24T08:17:26.591898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.optim import AdamW  # âœ… ìˆ˜ì •ë¨: PyTorch ë‚´ì¥ AdamW ì‚¬ìš©\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# GPU ì„¤ì • (ì—†ìœ¼ë©´ CPU ì‚¬ìš©)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"ğŸ”¥ í˜„ì¬ ì‚¬ìš© ì¥ì¹˜: {device}\")\n",
    "\n",
    "# í† í¬ë‚˜ì´ì € ë¡œë“œ (KoELECTRA)\n",
    "MODEL_NAME = \"monologg/koelectra-base-v3-discriminator\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text = str(self.texts[item])\n",
    "        label = self.labels[item]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# ë°ì´í„°ë¡œë” ìƒì„±\n",
    "# (train_texts, val_texts ë“±ì€ ë°©ê¸ˆ ì „ ë‹¨ê³„ì—ì„œ ì´ë¯¸ ë§Œë“¤ì–´ì ¸ ìˆìŠµë‹ˆë‹¤)\n",
    "train_dataset = ReviewDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = ReviewDataset(val_texts, val_labels, tokenizer)\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "print(\"âœ… ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ!\")"
   ],
   "id": "352ee9a5d100e6e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ í˜„ì¬ ì‚¬ìš© ì¥ì¹˜: cuda\n",
      "âœ… ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ!\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T08:20:43.383046Z",
     "start_time": "2025-11-24T08:20:42.357181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 5ê°œì˜ ë¼ë²¨(0~4)ë¡œ ë¶„ë¥˜í•˜ëŠ” ëª¨ë¸ ë¡œë“œ\n",
    "# ğŸš¨ weights_only=False ì˜µì…˜ì„ ì¶”ê°€í•˜ì—¬ ë²„ì „ ì˜¤ë¥˜ë¥¼ ìš°íšŒí•©ë‹ˆë‹¤.\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=5,\n",
    "    weights_only=False\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "# ì˜µí‹°ë§ˆì´ì € ì„¤ì •\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# ì •í™•ë„ ê³„ì‚° í•¨ìˆ˜\n",
    "def calc_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "print(\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\")"
   ],
   "id": "ada5c94778f5f05e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T08:21:28.700852Z",
     "start_time": "2025-11-24T08:20:45.339094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------------------------------------------------------\n",
    "# ğŸš¨ ìˆ˜ì • ì‚¬í•­: tqdm.notebook ëŒ€ì‹  ì¼ë°˜ tqdmì„ ì‚¬ìš©í•˜ì—¬ ì—ëŸ¬ ë°©ì§€\n",
    "from tqdm import tqdm\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "EPOCHS = 3\n",
    "\n",
    "print(f\"ğŸ”¥ í•™ìŠµ ì‹œì‘! (GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'Unknown'})\")\n",
    "print(f\"ì´ {EPOCHS} Epoch ë™ì•ˆ í•™ìŠµí•©ë‹ˆë‹¤.\\n\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"======== Epoch {epoch + 1} / {EPOCHS} ========\")\n",
    "\n",
    "    # [í•™ìŠµ ëª¨ë“œ]\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    train_acc = 0\n",
    "\n",
    "    # tqdm()ìœ¼ë¡œ ê°ì‹¸ì„œ ì§„í–‰ë¥  í‘œì‹œ\n",
    "    for batch in tqdm(train_loader, desc=\"Training\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ì •í™•ë„ ëˆ„ì \n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = labels.to('cpu').numpy()\n",
    "        train_acc += calc_accuracy(logits, label_ids)\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    avg_train_acc = train_acc / len(train_loader)\n",
    "\n",
    "    print(f\"  âœ… Average Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"  âœ… Average Train Accuracy: {avg_train_acc:.4f}\")\n",
    "\n",
    "    # [ê²€ì¦ ëª¨ë“œ]\n",
    "    model.eval()\n",
    "    val_acc = 0\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Validation\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            val_loss += outputs.loss.item()\n",
    "\n",
    "            logits = outputs.logits.detach().cpu().numpy()\n",
    "            label_ids = labels.to('cpu').numpy()\n",
    "            val_acc += calc_accuracy(logits, label_ids)\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    avg_val_acc = val_acc / len(val_loader)\n",
    "\n",
    "    print(f\"  ğŸ”¹ Validation Loss: {avg_val_loss:.4f}\")\n",
    "    print(f\"  ğŸ”¹ Validation Accuracy: {avg_val_acc:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print(\"\\nğŸ‰ ëª¨ë“  í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")"
   ],
   "id": "6122bff4e0048344",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ í•™ìŠµ ì‹œì‘! (GPU: NVIDIA GeForce RTX 4070)\n",
      "ì´ 3 Epoch ë™ì•ˆ í•™ìŠµí•©ë‹ˆë‹¤.\n",
      "\n",
      "======== Epoch 1 / 3 ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:13<00:00,  9.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… Average Train Loss: 1.3339\n",
      "  âœ… Average Train Accuracy: 0.4355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:01<00:00, 30.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ”¹ Validation Loss: 1.0890\n",
      "  ğŸ”¹ Validation Accuracy: 0.6387\n",
      "--------------------------------------------------\n",
      "======== Epoch 2 / 3 ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:13<00:00,  9.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… Average Train Loss: 0.8286\n",
      "  âœ… Average Train Accuracy: 0.7485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:01<00:00, 30.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ”¹ Validation Loss: 0.7000\n",
      "  ğŸ”¹ Validation Accuracy: 0.7695\n",
      "--------------------------------------------------\n",
      "======== Epoch 3 / 3 ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [00:13<00:00,  9.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… Average Train Loss: 0.6122\n",
      "  âœ… Average Train Accuracy: 0.7905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:01<00:00, 31.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ”¹ Validation Loss: 0.5684\n",
      "  ğŸ”¹ Validation Accuracy: 0.8105\n",
      "--------------------------------------------------\n",
      "\n",
      "ğŸ‰ ëª¨ë“  í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T08:21:29.159975Z",
     "start_time": "2025-11-24T08:21:28.704823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# í•™ìŠµëœ ëª¨ë¸ ì €ì¥\n",
    "save_path = \"../models/koelectra_finetuned/\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# ëª¨ë¸ ê°€ì¤‘ì¹˜ ì €ì¥\n",
    "torch.save(model.state_dict(), os.path.join(save_path, \"koelectra_model.pt\"))\n",
    "print(f\"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {save_path}koelectra_model.pt\")"
   ],
   "id": "92111fd1e6c0850a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: models/koelectra_finetuned/koelectra_model.pt\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "45dd6aa781688b89"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
